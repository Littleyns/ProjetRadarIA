{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7855929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "# Paramètres\n",
    "num_positions = 181\n",
    "num_time_steps = 5\n",
    "\n",
    "max_speed = 10.0  # Vitesse maximale\n",
    "\n",
    "all_examples = pd.DataFrame()\n",
    "\n",
    "for example_idx in range(100000):\n",
    "    doa_indices = [random.randint(30,150), random.randint(30,150)]\n",
    "    # Générer une série temporelle de 5 mesures associée à une vitesse\n",
    "    time_series_example = generate_time_series_example(num_positions, num_time_steps, doa_indices, max_speed)\n",
    "\n",
    "\n",
    "\n",
    "    # Ajouter la ligne à l'ensemble des exemples\n",
    "    all_examples = pd.concat([all_examples, time_series_example], axis=0, ignore_index=True)\n",
    "\n",
    "# Enregistrer toutes les séries temporelles dans un seul fichier CSV\n",
    "all_examples.to_csv('temporal_measures_trainset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d168191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series_example(num_positions, num_time_steps, doa_indices, max_speed):\n",
    "    # Générer une vitesse aléatoire pour chaque exemple\n",
    "    initial_doa_indices = doa_indices\n",
    "    speeds = []\n",
    "    for i in range(len(doa_indices)):\n",
    "        speed = (1,-1)[np.random.randint(0,2)==1]\n",
    "        if speed == 1:\n",
    "            speed*= random.randint(1, int((abs(180-doa_indices[i]))/num_time_steps))\n",
    "        else:\n",
    "            speed *= random.randint(1,int(doa_indices[i]/num_time_steps))\n",
    "        speeds+=speed,\n",
    "    # Normaliser la vitesse\n",
    "    #normalized_speed = speed / np.mean(speed)\n",
    "\n",
    "    # Initialiser une série temporelle de positions pour chaque exemple\n",
    "    time_series_positions = []\n",
    "\n",
    "    for _ in range(num_time_steps):\n",
    "        # Générer un vecteur de positions initialisé à zéro\n",
    "        positions = np.zeros(num_positions)\n",
    "\n",
    "        # Placer des '1' aux indices spécifiés pour les DoA\n",
    "        positions[list(doa_indices)] = 1\n",
    "\n",
    "        # Ajouter la série temporelle de positions à la liste\n",
    "        time_series_positions.append(positions)\n",
    "\n",
    "        # Mettre à jour les indices des DoA en fonction de la vitesse\n",
    "        doa_indices = np.array(doa_indices) + np.array(speeds)\n",
    "    # Créer un dataframe pandas avec la série temporelle de positions et la vitesse associée\n",
    "\n",
    "    time_series_positions= np.array(time_series_positions)\n",
    "    # Créer la DataFrame\n",
    "    df = pd.DataFrame({i: time_series_positions[i].reshape(1,181).tolist() for i in range(time_series_positions.shape[0])})\n",
    "\n",
    "    speeds_res = np.zeros(num_positions)\n",
    "    speeds_res[initial_doa_indices] = speeds\n",
    "    df['Speed'] = speeds_res.reshape(1,181).tolist()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path):\n",
    "  data = pd.read_csv(path,header=None, index_col=False)\n",
    "  X = data.iloc[1:,:5].values\n",
    "  y = data.iloc[1:,5].values\n",
    "  sy = list(map(lambda yy: yy.strip('][').split(', '),y))\n",
    "  y = np.array(sy).astype(np.float32)\n",
    "  X = np.array([ list(map(lambda mesure: mesure.strip('][').split(', '),X[i]))for i in range(len(X))]).astype(np.float32)\n",
    "  return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ca2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Générer une dataset de forme (n, 5, 181)\n",
    "# Remplacez cette partie avec votre propre génération de données\n",
    "X,y = get_dataset(\"temporal_measures_trainset.csv\")\n",
    "n = X.shape[0]\n",
    "\n",
    "# Créer le modèle RNN\n",
    "model = Sequential()\n",
    "model.add(LSTM(181, input_shape=(5, 181), activation='linear'))\n",
    "model.add(Dense(181, activation='linear'))\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2149155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.RNNmodel import RNNModel\n",
    "model = RNNModel()\n",
    "model.load(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe08194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire des prédictions sur de nouvelles données (remplacez avec vos données de test)\n",
    "Xtest,ytest = get_dataset(\"temporal_measures_testset.csv\")\n",
    "predictions = model.predict(Xtest)\n",
    "\n",
    "print(\"Predictions:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
